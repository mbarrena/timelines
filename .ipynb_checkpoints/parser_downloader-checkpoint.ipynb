{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import requests\n",
    "import unicodedata\n",
    "from PIL import Image\n",
    "\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizar_nombre(name):\n",
    "    return strip_accents((name.strip().replace(\" \", \"_\").replace(\"(\",\"\").replace(\")\",\"\")).lower())\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "# precondición: el campo imagen no es NaN\n",
    "def obtener_url_img(y):\n",
    "    url = y[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "def obtenerlink(y):\n",
    "    #print(y)\n",
    "    url = y[5].split('\":\"')[1]\n",
    "    url2 = url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "def quote(str):\n",
    "    return '\"'+str+'\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPRESAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Timeglider csv\n",
    "df = pd.read_csv(\"./linea_tiempo.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['startdate', ' enddate', ' title', ' description', ' importance',\n",
      "       ' link', ' icon', ' image', ' date_display', ' low threshold',\n",
      "       ' high threshold', ' y_position'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>Ledesma</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=199_...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://upload.wikimedia.org/wikipedia...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>Ferrocarril del Oeste</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=0B8E...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1865-07-02 00:28:00</td>\n",
       "      <td>1865-07-02 00:28:00</td>\n",
       "      <td>Semino</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1gSn...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://s3.amazonaws.com/timeglider_us...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1876-07-01 22:39:00</td>\n",
       "      <td>1876-07-01 22:39:00</td>\n",
       "      <td>Laboratorios Casasco</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1YlL...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://www.colfarma.info/colfarma/wp-...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1877-04-10 00:50:00</td>\n",
       "      <td>1877-04-10 00:50:00</td>\n",
       "      <td>CGFSA</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1aLF...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://static.wixstatic.com/media/89b...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             startdate              enddate                  title  \\\n",
       "0  1830-12-31 18:14:00  1830-12-31 18:14:00                Ledesma   \n",
       "1  1857-08-27 14:08:00  1857-08-27 14:08:00  Ferrocarril del Oeste   \n",
       "2  1865-07-02 00:28:00  1865-07-02 00:28:00                 Semino   \n",
       "3  1876-07-01 22:39:00  1876-07-01 22:39:00   Laboratorios Casasco   \n",
       "4  1877-04-10 00:50:00  1877-04-10 00:50:00                  CGFSA   \n",
       "\n",
       "   description   importance  \\\n",
       "0      <p></p>           50   \n",
       "1      <p></p>           50   \n",
       "2      <p></p>           50   \n",
       "3      <p></p>           50   \n",
       "4      <p></p>           50   \n",
       "\n",
       "                                                link  \\\n",
       "0  [{\"url\":\"https://drive.google.com/open?id=199_...   \n",
       "1  [{\"url\":\"https://drive.google.com/open?id=0B8E...   \n",
       "2  [{\"url\":\"https://drive.google.com/open?id=1gSn...   \n",
       "3  [{\"url\":\"https://drive.google.com/open?id=1YlL...   \n",
       "4  [{\"url\":\"https://drive.google.com/open?id=1aLF...   \n",
       "\n",
       "                       icon  \\\n",
       "0  shapes/triangle_gray.png   \n",
       "1  shapes/triangle_gray.png   \n",
       "2  shapes/triangle_gray.png   \n",
       "3  shapes/triangle_gray.png   \n",
       "4  shapes/triangle_gray.png   \n",
       "\n",
       "                                               image  date_display  \\\n",
       "0  {\"src\":\"https://upload.wikimedia.org/wikipedia...            da   \n",
       "1                                                NaN            da   \n",
       "2  {\"src\":\"https://s3.amazonaws.com/timeglider_us...            da   \n",
       "3  {\"src\":\"https://www.colfarma.info/colfarma/wp-...            da   \n",
       "4  {\"src\":\"https://static.wixstatic.com/media/89b...            da   \n",
       "\n",
       "    low threshold   high threshold   y_position  \n",
       "0               1              100            0  \n",
       "1               1              100            0  \n",
       "2               1              100            0  \n",
       "3               1              100            0  \n",
       "4               1              100            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually filtering some data and fixing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ledesma' 'Ferrocarril del Oeste' 'Semino' 'Laboratorios Casasco' 'CGFSA'\n",
      " 'Aguila Saint' 'Hesperdina' 'Rigolleau'\n",
      " 'Fábrica Argentina de Alpargatas (2)'\n",
      " 'Fábrica Argentina de Alpargatas (1)' 'Frigorífico Anglo' 'Bunge y Born'\n",
      " 'Alpargatas (1)' 'Alpargatas (2)' 'Quilmes' 'La Matrona' 'Grimoldi'\n",
      " 'Cerro Negro' 'British American Tabacco' 'Pirelli (2)' 'Pirelli (1)'\n",
      " 'La Martona' 'Molinos Río de la Plata S.A.' 'La Cantábrica'\n",
      " 'Molinos Río de la Plata' 'Banco Galicia' 'Swift' 'Frávega' 'Ferrum (2)'\n",
      " 'Bayer Argentina S.A.' 'Ferrum (1)' 'SIAM (2)' 'SIAM (1)' 'Terrabusi'\n",
      " 'Cerveza Schneider' 'Obras Sanitarias de la Nación' 'BGH' 'FORD'\n",
      " 'Shell (2)' 'Shell (1)' 'Firestone' 'Goodyear' 'Kodak' 'Longvie' 'FIAT'\n",
      " 'Roemmers' 'YPF (3)' 'YPF (2)' 'YPF (1)'\n",
      " 'Frigorífico Lisandro de la Torre (1)'\n",
      " 'Frigorífico Lisandro de la Torre (2)' 'Estancias Las Marías, Taragüi'\n",
      " 'General Motors (1)' 'General Motors (2)' 'Felfort (2)' 'Felfort (1)'\n",
      " 'Loma Negra' 'Milkaut' 'Colgate - Palmolive' 'La Serenísima (1)'\n",
      " 'La serenísima (2)' 'La serenísima (3)' 'Johnson &amp; Johnson'\n",
      " 'Molina Cañuelas' 'PHILCO' 'Bagó' 'Phillips' 'SanCor' 'Fernet Branca'\n",
      " 'Dirección General de Fabricaciones Militares' 'Acindar' 'Coca-Cola'\n",
      " 'Altos Hornos Zapla' 'Guaymallén' 'Techint' 'Entel (2)' 'Gas del Estado'\n",
      " 'Entel (1)' 'Havanna (1)' 'Havanna (2)' 'Aerolíneas Argentinas (3)'\n",
      " 'Aerolíneas Argentinas (1)' 'Aerolineas Argentinas (2)' 'Tenaris'\n",
      " 'Arcor (2)' 'Arcor (1)' 'Arcor (3)' 'Arcor (4)' 'Televisión Pública'\n",
      " 'Embalse de Río Hondo' 'Astillero Río Santiago'\n",
      " 'Industrias Kaiser Argentina S.A.' 'Correo OCA' 'Flecha Bus' 'Oslé'\n",
      " 'Peugeot' 'ELMA' 'Canal 13' 'Telefe' 'LOréal' 'Chocón-Cerros colorados'\n",
      " 'Central Hidroeléctrica Pueblo Viejo (1)'\n",
      " 'Central Hidroeléctrica Pueblo Viejo (2)' 'Don Satur'\n",
      " 'Banco Santander Río' 'Freddo' 'Corven' 'ALUAR' 'Correo Argentino'\n",
      " 'Sheraton' 'Represa el Chocón' 'Karavell' 'Represa Yacyretá'\n",
      " 'Central Nuclear Atucha' 'Pumper Nic' 'Renault Argentina (2)'\n",
      " 'Renault Argentina (1)' 'Banco Macro' 'Cerámica Fasinpát (ex Zanón)'\n",
      " 'Zanón (2)' 'Día' 'Cablevisión' 'Banco Comafi'\n",
      " 'Central Hidroeléctrica Río Grande' 'Arcos Dorados S.A.' 'Coto' 'Movicom'\n",
      " 'Telecentro' 'Edenor' 'UNSAM' 'Motomel' 'Pepsico Argentina' 'FARMACITY'\n",
      " 'Ampliación Av. General Paz' 'Despegar' 'Mercado Libre' 'Hilton' 'Grido'\n",
      " 'Crocs' 'CTI Móvil - Claro Argentina'\n",
      " 'Paseo Bajo nivel de Villa Ballester']\n"
     ]
    }
   ],
   "source": [
    "print(df[' title'].unique())\n",
    "alpargatas=[\"Fábrica Argentina de Alpargatas\",\"Alpargatas\"] #multiple, deberían ser en 1883 todos # pasa a ser Alpargatas\n",
    "ferrum=[\"Ferrum\"]\n",
    "siam=[\"SIAM\"]\n",
    "pirelli=[\"Pirelli\"]\n",
    "shell = [\"Shell\"]\n",
    "ypf = [\"YPF\"]\n",
    "torre = [\"Frigorífico Lisandro de la Torre\"]\n",
    "gm = [\"General Motors\"]\n",
    "felfort = [\"Felfort\"]\n",
    "sere=[\"La Serenísima\"]\n",
    "entel = [\"Entel\"]\n",
    "havanna = [\"Havanna\"]\n",
    "aa = [\"Aerolíneas Argentinas\"]\n",
    "arcor = [\"Arcor\"]\n",
    "pv = [\"Central Hidroeléctrica Pueblo Viejo\"]\n",
    "renault = [\"Renault Argentina\"]\n",
    "zanon = [\"Cerámica Fasinpát (ex Zanón)\", \"Zanón\"] #pasa a ser Zanón\n",
    "casasco = [\"Laboratorios Casasco\"]\n",
    "milkaut = [\"Milkaut\"]\n",
    "banco_macro = [\"Banco Macro\"]\n",
    "multiples = [\"Alpargatas\",\"Ferrum\",\"SIAM\",\"Pirelli\",\"Shell\",\"YPF\",\"Frigorífico Lisandro de la Torre\",\"General Motors\",\"Felfort\",\"La Serenísima\",\"Entel\",\"Havanna\",\"Aerolíneas Argentinas\",\"Arcor\",\"Central Hidroeléctrica Pueblo Viejo\",\"Renault Argentina\",\"Zanón\",\"Laboratorios Casasco\",\"Milkaut\",\"Banco Macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALUAR', 'Acindar', 'Aerolíneas Argentinas', 'Aguila Saint', 'Alpargatas', 'Altos Hornos Zapla', 'Ampliación Av. General Paz', 'Arcor', 'Arcos Dorados S.A.', 'Astillero Río Santiago', 'BGH', 'Bagó', 'Banco Comafi', 'Banco Galicia', 'Banco Macro', 'Banco Santander Río', 'Bayer Argentina S.A.', 'British American Tabacco', 'Bunge y Born', 'CGFSA', 'CTI Móvil - Claro Argentina', 'Cablevisión', 'Canal 13', 'Central Hidroeléctrica Pueblo Viejo', 'Central Hidroeléctrica Río Grande', 'Central Nuclear Atucha', 'Cerro Negro', 'Cerveza Schneider', 'Cerámica Fasinpát (ex Zanón)', 'Chocón-Cerros colorados', 'Coca-Cola', 'Colgate - Palmolive', 'Correo Argentino', 'Correo OCA', 'Corven', 'Coto', 'Crocs', 'Despegar', 'Dirección General de Fabricaciones Militares', 'Don Satur', 'Día', 'ELMA', 'Edenor', 'Embalse de Río Hondo', 'Entel', 'Estancias Las Marías, Taragüi', 'FARMACITY', 'FIAT', 'FORD', 'Felfort', 'Fernet Branca', 'Ferrocarril del Oeste', 'Ferrum', 'Firestone', 'Flecha Bus', 'Freddo', 'Frigorífico Anglo', 'Frigorífico Lisandro de la Torre', 'Frávega', 'Fábrica Argentina de Alpargatas', 'Gas del Estado', 'General Motors', 'Goodyear', 'Grido', 'Grimoldi', 'Guaymallén', 'Havanna', 'Hesperdina', 'Hilton', 'Industrias Kaiser Argentina S.A.', 'Johnson &amp; Johnson', 'Karavell', 'Kodak', 'LOréal', 'La Cantábrica', 'La Martona', 'La Matrona', 'La Serenísima', 'Laboratorios Casasco', 'Ledesma', 'Loma Negra', 'Longvie', 'Mercado Libre', 'Milkaut', 'Molina Cañuelas', 'Molinos Río de la Plata', 'Molinos Río de la Plata S.A.', 'Motomel', 'Movicom', 'Obras Sanitarias de la Nación', 'Oslé', 'PHILCO', 'Paseo Bajo nivel de Villa Ballester', 'Pepsico Argentina', 'Peugeot', 'Phillips', 'Pirelli', 'Pumper Nic', 'Quilmes', 'Renault Argentina', 'Represa Yacyretá', 'Represa el Chocón', 'Rigolleau', 'Roemmers', 'SIAM', 'SanCor', 'Semino', 'Shell', 'Sheraton', 'Swift', 'Techint', 'Telecentro', 'Telefe', 'Televisión Pública', 'Tenaris', 'Terrabusi', 'UNSAM', 'YPF']\n"
     ]
    }
   ],
   "source": [
    "lst = ['Ledesma','Ferrocarril del Oeste','Semino','Laboratorios Casasco','CGFSA','Aguila Saint', 'Hesperdina', 'Rigolleau','Fábrica Argentina de Alpargatas', 'Frigorífico Anglo', 'Bunge y Born','Alpargatas', 'Quilmes', 'La Matrona', 'Grimoldi','Cerro Negro', 'British American Tabacco', 'Pirelli','La Martona', 'Molinos Río de la Plata S.A.', 'La Cantábrica','Molinos Río de la Plata', 'Banco Galicia', 'Swift', 'Frávega','Bayer Argentina S.A.', 'Ferrum', 'SIAM', 'Terrabusi','Cerveza Schneider', 'Obras Sanitarias de la Nación', 'BGH', 'FORD', 'Shell', 'Firestone', 'Goodyear', 'Kodak', 'Longvie', 'FIAT','Roemmers', 'YPF','Frigorífico Lisandro de la Torre', 'Estancias Las Marías, Taragüi','General Motors', 'Felfort','Loma Negra', 'Milkaut', 'Colgate - Palmolive', 'La Serenísima', 'Johnson &amp; Johnson','Molina Cañuelas', 'PHILCO', 'Bagó', 'Phillips', 'SanCor', 'Fernet Branca','Dirección General de Fabricaciones Militares', 'Acindar', 'Coca-Cola','Altos Hornos Zapla', 'Guaymallén', 'Techint', 'Gas del Estado','Entel', 'Havanna','Aerolíneas Argentinas', 'Tenaris', 'Arcor', 'Televisión Pública','Embalse de Río Hondo', 'Astillero Río Santiago','Industrias Kaiser Argentina S.A.', 'Correo OCA', 'Flecha Bus', 'Oslé','Peugeot', 'ELMA', 'Canal 13', 'Telefe', 'LOréal', 'Chocón-Cerros colorados','Central Hidroeléctrica Pueblo Viejo', 'Don Satur','Banco Santander Río', 'Freddo', 'Corven', 'ALUAR', 'Correo Argentino','Sheraton', 'Represa el Chocón', 'Karavell', 'Represa Yacyretá','Central Nuclear Atucha', 'Pumper Nic','Renault Argentina', 'Banco Macro', 'Cerámica Fasinpát (ex Zanón)', 'Día', 'Cablevisión', 'Banco Comafi','Central Hidroeléctrica Río Grande', 'Arcos Dorados S.A.', 'Coto', 'Movicom','Telecentro', 'Edenor', 'UNSAM', 'Motomel', 'Pepsico Argentina', 'FARMACITY','Ampliación Av. General Paz', 'Despegar', 'Mercado Libre', 'Hilton', 'Grido','Crocs', 'CTI Móvil - Claro Argentina','Paseo Bajo nivel de Villa Ballester'\n",
    "]\n",
    "lst.sort()\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes this cell has to be ran twice\n",
    "filtro_alpargatas = (df[' title'].str.contains(alpargatas[0])) | (df[' title'].str.contains(alpargatas[1]))\n",
    "#df.loc[filtro_alpargatas,' title'] = \"Alpargatas\"\n",
    "df[filtro_alpargatas].head()\n",
    "for i in range(df[filtro_alpargatas].count()[0]):\n",
    "    df.loc[filtro_alpargatas,' title'].iloc[i] = \"Alpargatas (\"+str(i)+\")\"\n",
    "#df.loc[9,' title'] = \"Alpargatas (2)\"\n",
    "#df.loc[12,' title'] = \"Alpargatas (3)\"\n",
    "#df.loc[13,' title'] = \"Alpargatas (4)\"\n",
    "\n",
    "filtro_zanon = (df[' title'].str.contains(zanon[0])) | (df[' title'].str.contains(zanon[1]))\n",
    "df[filtro_zanon].head()\n",
    "for i in range(df[filtro_zanon].count()[0]):\n",
    "    df.loc[filtro_zanon,' title'].iloc[i] = \"Zanón (\"+str(i)+\")\"\n",
    "#df.loc[118,' title'] = \"Zanón (1)\"\n",
    "#df.loc[199,' title'] = \"Zanón (2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events based on timeglider csv (migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>Banco Macro (1)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=10Zg...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://s3.amazonaws.com/timeglider_us...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>Banco Macro (2)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=165G...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>0</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               startdate              enddate            title  description  \\\n",
       "130  1978-09-04 11:53:00  1978-09-04 11:53:00  Banco Macro (1)      <p></p>   \n",
       "131  1978-09-04 23:57:00  1978-09-04 23:57:00  Banco Macro (2)      <p></p>   \n",
       "\n",
       "      importance                                               link  \\\n",
       "130           50  [{\"url\":\"https://drive.google.com/open?id=10Zg...   \n",
       "131           50  [{\"url\":\"https://drive.google.com/open?id=165G...   \n",
       "\n",
       "                         icon  \\\n",
       "130  shapes/triangle_gray.png   \n",
       "131  shapes/triangle_gray.png   \n",
       "\n",
       "                                                 image  date_display  \\\n",
       "130  {\"src\":\"https://s3.amazonaws.com/timeglider_us...            da   \n",
       "131                                                  0            da   \n",
       "\n",
       "      low threshold   high threshold   y_position  \n",
       "130               1              100            0  \n",
       "131               1              100            0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscamos crear algo de esta pinta:\n",
    "'''\n",
    "var items = new vis.DataSet([\n",
    "{id: 1, content: 'item 1', start: '2014-04-20'},\n",
    "{id: 2, content: 'item 2', start: '2014-04-14'},\n",
    "{id: 3, content: 'item 3', start: '2014-04-18'},\n",
    "{id: 4, content: 'item 4', start: '2014-04-16', end: '2014-04-19'},\n",
    "{id: 5, content:  createItem(\"item 5\",'./img/swift.jpg',[\"https://makobot-prod.github.io/timelines/\",\"blabla\"])  , start: '2014-04-25'},\n",
    "{id: 6, content: 'item 6', start: '2014-04-27', type: 'point'}\n",
    "]);\n",
    "'''\n",
    "df[' image'] = df[' image'].fillna(0)\n",
    "### PARECERÍA ESTAR ANDANDO\n",
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[2])\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    name_empresa = x[2]\n",
    "    \n",
    "    if(multiples.count(x[2][:-4])==0):\n",
    "        links = \"[\"+ quote(obtenerlink(x)) + \"]\" #crear esta func\n",
    "    else:\n",
    "        #tengo multiples trabajos de esta empresa\n",
    "        #en algun lado me tengo que guardar los múltiples\n",
    "        name_empresa = x[2][:-4]\n",
    "        idn = idn[:-2]\n",
    "        filtro = df[' title'].str.contains(x[2][:-4])\n",
    "        df_links = df[filtro]\n",
    "        links = \"[\"\n",
    "        df_links = df_links.apply(obtenerlink,axis=1)\n",
    "        for item in df_links.iteritems():\n",
    "            url = item[1]\n",
    "            links += quote(url) + \",\"\n",
    "        links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    if(x[7]!= 0):\n",
    "        path_img = quote('./img/'+idn+'.png')\n",
    "        im = Image.open('./timelines/img/'+idn+'.png')\n",
    "        width, height = im.size\n",
    "        width = int(width*48/height)\n",
    "    \n",
    "    content  = \"createItem(\"+ quote(name_empresa) +\",\"+ path_img +\",\"+ str(width) +\",\"+ links + \")\"\n",
    "    \n",
    "    return \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start + \"}\"\n",
    "            \n",
    "#crear_evento(df.loc[118])\n",
    "#df.loc[118]\n",
    "filtro = df[' title'].str.contains(\"Banco Macro\")\n",
    "df[filtro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "df_sin_repes = df.copy()\n",
    "filtro_repes = (df[' title'].str.contains(\"\\(\")) & (~(df[' title'].str.contains(\"\\(1\\)\")))\n",
    "df_sin_repes = df_sin_repes[~filtro_repes]\n",
    "\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "#f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "cosas = df_sin_repes.apply(crear_evento,axis=1)\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./timelines/empresas/trabajos_appendable.js\" \"./timelines/trabajos.js\"\n",
    "\n",
    "f2 = open(\"./timelines/empresas/trabajos.js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizer (OVERWRITES IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBSOLETE: images are not that heavy and look better without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded /tmp/magick-3689dVLyjnH2RKVf. Dimensions: 560 x 210  (with alpha). Format: lossless. Now saving...\n",
      "Saved file /tmp/magick-3689r4TsGY9Aa3Al\n",
      "convert-im6.q16: improper image header `./timelines/img/coto.png' @ error/png.c/ReadPNGImage/3954.\n",
      "convert-im6.q16: improper image header `./timelines/img/sheraton.png' @ error/png.c/ReadPNGImage/3954.\n"
     ]
    }
   ],
   "source": [
    "#!convert \"./timelines/empresas/img/*.png\" -filter Lanczos -resize x48 -sharpen 0x.5 -set filename:base \"%[basename]\" \"./timelines/empresas/img/%[filename:base].png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete _1 from filename for images that end in _1\n",
    "#!for file in `find . -name '*_1.png'` ; do mv \"$file\" \"${file%_1.png}.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline event images downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\", \"local-filename.jpg\")\n",
    "# Quiero hacer una función que, dada una fila, me baje la imagen\n",
    "df_img=df.copy()\n",
    "df_img.dropna(subset=[' image'], inplace=True) \n",
    "falladas=[]\n",
    "assert(False)\n",
    "#path = \"./img_originales/\"\n",
    "def image_download(x):\n",
    "    empresa=sanitizar_nombre(x[2])\n",
    "    # donde x es una serie de Pandas\n",
    "    url = x[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    print(url2)\n",
    "    try:\n",
    "        #response = requests.get(url2)\n",
    "        print(\"Downloading img for\",empresa)\n",
    "        urllib.request.urlretrieve(url2, path + empresa.lower() + \".png\")\n",
    "    except Exception as exc:\n",
    "        print('[!!!] {err}'.format(err=exc),\"retrieving img for\", empresa ,\"aborted\")\n",
    "        falladas.append(empresa)\n",
    "\n",
    "for index, row in df_img.iterrows():\n",
    "    print(index)\n",
    "    image_download(df_img.loc[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cgfsa', 'correo_oca', 'don_satur', 'sheraton', 'arcos_dorados_s.a.', 'telecentro']\n"
     ]
    }
   ],
   "source": [
    "print(falladas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not np.isnan(df.loc[1][7].isnull()):\n",
    "    print(\"Not a nan\")\n",
    "    print(df.loc[1][7])\n",
    "    urllib.request.urlretrieve(df.loc[1][7], path+df.loc[1][2].lower()+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTORIC EVENTS TIMELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_name=\"4unidad\"\n",
    "df = pd.read_csv(\"./\"+unit_name+\"/\"+unit_name+\".csv\",index_col=False)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "logo_info = \"www.cooperacion2005.es\"\n",
    "logo_tour = \"guejarsierra.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>lowthreshold</th>\n",
       "      <th>highthreshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1929-10-24 20:56:00</td>\n",
       "      <td>1929-10-24 20:56:00</td>\n",
       "      <td>24-10-1929: crack de la Bolsa de New York</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>75</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/file/d/1FRG8...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930-01-01 18:22:00</td>\n",
       "      <td>1930-01-01 18:22:00</td>\n",
       "      <td>Década de 1930: contexto histórico internacional</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/file/d/1dw-R...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1930-01-18 20:56:00</td>\n",
       "      <td>1930-01-18 20:56:00</td>\n",
       "      <td>18-01-1930: intento frustrado de firmar el con...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1930-07-01 20:56:00</td>\n",
       "      <td>1930-07-01 20:56:00</td>\n",
       "      <td>1930: Gran Depresión del 30</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ye</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1930-07-01 20:56:00</td>\n",
       "      <td>1930-07-01 20:56:00</td>\n",
       "      <td>1930 al 1936: &amp;#34;nacionalismo oligárquico&amp;#3...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ye</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             startdate              enddate  \\\n",
       "0  1929-10-24 20:56:00  1929-10-24 20:56:00   \n",
       "1  1930-01-01 18:22:00  1930-01-01 18:22:00   \n",
       "2  1930-01-18 20:56:00  1930-01-18 20:56:00   \n",
       "3  1930-07-01 20:56:00  1930-07-01 20:56:00   \n",
       "4  1930-07-01 20:56:00  1930-07-01 20:56:00   \n",
       "\n",
       "                                               title description  importance  \\\n",
       "0          24-10-1929: crack de la Bolsa de New York     <p></p>          75   \n",
       "1   Década de 1930: contexto histórico internacional     <p></p>          60   \n",
       "2  18-01-1930: intento frustrado de firmar el con...     <p></p>          60   \n",
       "3                        1930: Gran Depresión del 30     <p></p>          75   \n",
       "4  1930 al 1936: &#34;nacionalismo oligárquico&#3...     <p></p>          60   \n",
       "\n",
       "                                                link  \\\n",
       "0  [{\"url\":\"https://drive.google.com/file/d/1FRG8...   \n",
       "1  [{\"url\":\"https://drive.google.com/file/d/1dw-R...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                       icon  \\\n",
       "0  shapes/triangle_gray.png   \n",
       "1  shapes/triangle_gray.png   \n",
       "2  shapes/triangle_gray.png   \n",
       "3  shapes/triangle_gray.png   \n",
       "4  shapes/triangle_gray.png   \n",
       "\n",
       "                                               image date_display  \\\n",
       "0  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "1  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "2                                                NaN           da   \n",
       "3                                                NaN           ye   \n",
       "4                                                NaN           ye   \n",
       "\n",
       "   lowthreshold  highthreshold  y_position  \n",
       "0             1            100           0  \n",
       "1             1            100           0  \n",
       "2             1            100           0  \n",
       "3             1            100           0  \n",
       "4             1            100           0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informacion\n"
     ]
    }
   ],
   "source": [
    "# Identify type of timeline event (general information (logo_info) vs tourist information (logo_tour))\n",
    "def find_type(event):\n",
    "    if(not pd.isnull(event[7])):\n",
    "        #not a NaN\n",
    "        if(event[7][15:37]==logo_info):\n",
    "            return \"informacion\"\n",
    "        elif(event[7][15:31]==logo_tour):\n",
    "            return \"turismo\"\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(find_type(df.iloc[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrate events from Timeglider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['07-09-1930:_ministro_de_economia_e.', '2-5-1935:_fundacion_del_iram_en_arg', '27-11-1943:_peron_es_designado_secr', '06_y_09-08-1945:_bombardeos_atomico']\n"
     ]
    }
   ],
   "source": [
    "# First, we must identify possible repeated events\n",
    "\n",
    "def sanitizar_nombre(name):\n",
    "    return strip_accents((name.strip().replace(\" \", \"_\").replace(\"(\",\"\").replace(\")\",\"\")).lower()).replace('&#34;','')\n",
    "\n",
    "def get_name(x):\n",
    "    sanitized = sanitizar_nombre(x[2])\n",
    "    return sanitized[:35]\n",
    "\n",
    "names = df.apply(get_name,axis=1)\n",
    "seen = set()\n",
    "check_repeats = []\n",
    "for x in names:\n",
    "    if x not in seen:\n",
    "        seen.add(x)\n",
    "    else:\n",
    "        check_repeats.append(x)\n",
    "handled_repeats=[]\n",
    "print(check_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: {id: \"06-09-1930_golpe_de_estado_de_uribu\", content: \"06-09-1930 Golpe de Estado de Uriburu (bis)\", image:\"../img/informacion.svg\", link:\"https://drive.google.com/file/d/1gCIWrsk8TO1PMrxQ72PxFs8Gbx7flpPk/view?usp=sharing\", start: \"1930-09-06\"}\n",
      "['07-09-1930:_ministro_de_economia_e.', '2-5-1935:_fundacion_del_iram_en_arg', '27-11-1943:_peron_es_designado_secr', '06_y_09-08-1945:_bombardeos_atomico']\n"
     ]
    }
   ],
   "source": [
    "def crear_evento(x):\n",
    "    idn = get_name(x)\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    end = \"0\"\n",
    "    if(x[0][:-9] != x[1][:-9]):\n",
    "        end = quote(x[1][:-9])\n",
    "    \n",
    "    name_event = x[2].replace(\"&#34;\", '\\\\\"')\n",
    "    count_links = 0\n",
    "    \n",
    "    \n",
    "    if(check_repeats.count(idn)==0):\n",
    "        #Event is not repeated\n",
    "        if(not pd.isnull(x[5])):\n",
    "            count_links = 1\n",
    "            links = \"[\"+ quote(obtenerlink(x)) + \"]\" \n",
    "    else:\n",
    "        if(handled_repeats.count(idn)!=0):\n",
    "            raise Exception(\"Event already created\") \n",
    "        handled_repeats.append(idn) #we only want one event with all the data\n",
    "        if(not pd.isnull(x[5])):\n",
    "            count_links = 2 #more than 1 link = more than 1 work on same event\n",
    "            filtro = df['title'].str.contains(x[2][:21])\n",
    "            df_links = df[filtro]\n",
    "            links = \"[\"\n",
    "            df_links = df_links.apply(obtenerlink,axis=1)\n",
    "            for item in df_links.iteritems():\n",
    "                url = item[1]\n",
    "                links += quote(url) + \",\"\n",
    "            links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    \n",
    "    if(pd.isnull(x[5])):\n",
    "        links = \"[\"+\"]\"\n",
    "    \n",
    "    img = find_type(x)\n",
    "    content  = quote(name_event) \n",
    "    \n",
    "    if(img!= 0):\n",
    "        #if there is an image, include image\n",
    "        path_img = quote('../img/'+img+'.svg')\n",
    "        content += \", image:\"+ path_img \n",
    "        \n",
    "    if(count_links>1):\n",
    "        #if there is multiple links, pass list of links\n",
    "        content += \", links:\" + links\n",
    "    elif(count_links==1):\n",
    "        #if there is only one link, pass single link\n",
    "        content += \", link:\" + links[1:][:-1]\n",
    "    \n",
    "    res = \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start \n",
    "    if(end!=\"0\"):\n",
    "        res += \", end: \" + end\n",
    "        \n",
    "    res += \"}\"\n",
    "    return res\n",
    "\n",
    "def try_create(x):\n",
    "    try:\n",
    "        return crear_evento(x)\n",
    "        # If exception is raised, no return\n",
    "    except Exception as exc:\n",
    "        print('[!!!] Evento repetido:',x[2])\n",
    "\n",
    "print(\"event:\",crear_evento(df.iloc[5]))\n",
    "print(handled_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "[!!!] Evento repetido: 07-09-1930: Ministro de Economía E. Pérez (hasta 16-04-1931)\n",
      "[!!!] Evento repetido: 2-5-1935: fundación del IRAM en Argentina\n",
      "[!!!] Evento repetido: 27-11-1943: Perón es designado Secretario de Trabajo y Previsión\n",
      "[!!!] Evento repetido: 06 y 09-08-1945: bombardeos atómicos de Hiroshima y Nagasaki, respectivamente\n",
      "[!!!] Evento repetido: 06 y 09-08-1945: bombardeos atómicos de Hiroshima y Nagasaki, respectivamente\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "handled_repeats = []\n",
    "\n",
    "f = open(\"./\"+unit_name+\"/\"+unit_name+\"_appendable.js\", \"w\")\n",
    "f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "df_copy = df.copy()\n",
    "cosas = df_copy.apply(try_create,axis=1)\n",
    "cosas = cosas.dropna()\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./{unit_name}/{unit_name}_appendable.js\" \"./{unit_name}/{unit_name}.js\"\n",
    "\n",
    "f2 = open(\"./\"+unit_name+\"/\"+unit_name+\".js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./\"+unit_name+\"/\"+unit_name+\"_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New events from google forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>img</th>\n",
       "      <th>work</th>\n",
       "      <th>present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llao Llao Hotel &amp; Resort Golf-Spa</td>\n",
       "      <td>27/9/2020</td>\n",
       "      <td>./img/llao_llao_hotel_&amp;_resort_golf-spa.png</td>\n",
       "      <td>https://drive.google.com/file/d/1C7i8-12lf2cG5...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Paulina</td>\n",
       "      <td>8/6/1921</td>\n",
       "      <td>./img/la_paulina.png</td>\n",
       "      <td>https://drive.google.com/file/d/1PL5rrj5FxHQfM...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marolio</td>\n",
       "      <td>1/1/1950</td>\n",
       "      <td>./img/marolio.png</td>\n",
       "      <td>https://drive.google.com/file/d/1PI-JZWnAGplNZ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Tortoni</td>\n",
       "      <td>1/6/1858</td>\n",
       "      <td>./img/cafe_tortoni.png</td>\n",
       "      <td>https://drive.google.com/file/d/1GdkkGuiUMhfZr...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pizzini</td>\n",
       "      <td>1/1/1955</td>\n",
       "      <td>0</td>\n",
       "      <td>https://drive.google.com/file/d/10zAfBOqmS4s0B...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La Virginia</td>\n",
       "      <td>29/11/1915</td>\n",
       "      <td>./img/la_virginia.png</td>\n",
       "      <td>https://drive.google.com/file/d/1p96yyX2KoC-Ln...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La Cachuera</td>\n",
       "      <td>8/6/1901</td>\n",
       "      <td>./img/la_cachuera.png</td>\n",
       "      <td>https://drive.google.com/file/d/1-wk9heUUpr3T4...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEGBA (Servicios Eléctricos del Gran Buenos Ai...</td>\n",
       "      <td>1/10/1958</td>\n",
       "      <td>./img/segba_servicios_electricos_del_gran_buen...</td>\n",
       "      <td>https://drive.google.com/file/d/19idXKDm4ZOf5Q...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>28/5/1937</td>\n",
       "      <td>./img/volkswagen.png</td>\n",
       "      <td>https://drive.google.com/file/d/1yAGqeqnvtRvd7...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hotel Alvear Palace</td>\n",
       "      <td>1/1/1932</td>\n",
       "      <td>./img/hotel_alvear_palace.png</td>\n",
       "      <td>https://drive.google.com/file/d/1NHDqKt05jC-D0...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name        date  \\\n",
       "0                  Llao Llao Hotel & Resort Golf-Spa   27/9/2020   \n",
       "1                                        La Paulina     8/6/1921   \n",
       "2                                           Marolio     1/1/1950   \n",
       "3                                       Cafe Tortoni    1/6/1858   \n",
       "4                                            Pizzini    1/1/1955   \n",
       "5                                        La Virginia  29/11/1915   \n",
       "6                                        La Cachuera    8/6/1901   \n",
       "7  SEGBA (Servicios Eléctricos del Gran Buenos Ai...   1/10/1958   \n",
       "8                                         Volkswagen   28/5/1937   \n",
       "9                                Hotel Alvear Palace    1/1/1932   \n",
       "\n",
       "                                                 img  \\\n",
       "0        ./img/llao_llao_hotel_&_resort_golf-spa.png   \n",
       "1                               ./img/la_paulina.png   \n",
       "2                                  ./img/marolio.png   \n",
       "3                             ./img/cafe_tortoni.png   \n",
       "4                                                  0   \n",
       "5                              ./img/la_virginia.png   \n",
       "6                              ./img/la_cachuera.png   \n",
       "7  ./img/segba_servicios_electricos_del_gran_buen...   \n",
       "8                               ./img/volkswagen.png   \n",
       "9                      ./img/hotel_alvear_palace.png   \n",
       "\n",
       "                                                work present  \n",
       "0  https://drive.google.com/file/d/1C7i8-12lf2cG5...      No  \n",
       "1  https://drive.google.com/file/d/1PL5rrj5FxHQfM...      No  \n",
       "2  https://drive.google.com/file/d/1PI-JZWnAGplNZ...      No  \n",
       "3  https://drive.google.com/file/d/1GdkkGuiUMhfZr...      No  \n",
       "4  https://drive.google.com/file/d/10zAfBOqmS4s0B...      No  \n",
       "5  https://drive.google.com/file/d/1p96yyX2KoC-Ln...      No  \n",
       "6  https://drive.google.com/file/d/1-wk9heUUpr3T4...      No  \n",
       "7  https://drive.google.com/file/d/19idXKDm4ZOf5Q...      No  \n",
       "8  https://drive.google.com/file/d/1yAGqeqnvtRvd7...      No  \n",
       "9  https://drive.google.com/file/d/1NHDqKt05jC-D0...      No  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./empresas/new_groups.csv\",index_col=False)\n",
    "df['img'] = df['img'].fillna(0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuevas empresas (no aparecieron antes en la linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "df = df[df['present']=='No']\n",
    "#Necesito ver si hay repetidos dentro de las entregas nuevas\n",
    "#First, we must identify possible repeated events among new entries\n",
    "\n",
    "def get_name(x):\n",
    "    return sanitizar_nombre(x[0])\n",
    "\n",
    "#Generamos lista de elementos repetidos entre los nuevos, contra la que chequearemos para no agregarlos mas de una vez\n",
    "names = df.apply(get_name,axis=1)\n",
    "seen = set()\n",
    "check_repeats = []\n",
    "for x in names:\n",
    "    if x not in seen:\n",
    "        seen.add(x)\n",
    "    else:\n",
    "        check_repeats.append(x)\n",
    "handled_repeats=[]\n",
    "print(check_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: {id: \"pizzini\", content: createItem(\"Pizzini\",\"0\",0,[\"https://drive.google.com/file/d/10zAfBOqmS4s0BoeDtpvH2u90RHUBV-XZ/view?usp=drivesdk\"]), start: \"1955-1-1\"}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def parseDate(date):\n",
    "    numbers = date.split(\"/\")\n",
    "    return numbers[2]+\"-\"+numbers[1]+\"-\"+numbers[0]\n",
    "  \n",
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[0])\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(parseDate(x[1]))\n",
    "    name_empresa = x[0]\n",
    "    count_links = 0\n",
    "    \n",
    "    if(not pd.isnull(x[3])):\n",
    "        if(check_repeats.count(idn)==0):\n",
    "            #Event is not repeated\n",
    "            count_links = 1\n",
    "            links = \"[\"+ quote(x[3]) + \"]\" \n",
    "        else:\n",
    "            print(handled_repeats)\n",
    "            if(handled_repeats.count(idn)!=0):\n",
    "                print('[!!!] Evento repetido:',x[0])\n",
    "                raise Exception(\"Event already created\") #Cancel processing if event was already created for this enterprise\n",
    "            handled_repeats.append(idn) #we only want one event with all the data\n",
    "            count_links = 2 #more than 1 link = more than 1 work on same event\n",
    "            filtro = df['name'].str.contains(x[0])\n",
    "            df_links = df[filtro]\n",
    "            links = \"[\"\n",
    "            for item in df_links.iteritems():\n",
    "                print(item)\n",
    "                raise Exception(\"Testear que esto funcione\") \n",
    "                url = item[2]\n",
    "                links += quote(url) + \",\"\n",
    "            links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    else:\n",
    "        links = \"[\"+\"]\"\n",
    "    \n",
    "    if(x[2]!= 0):\n",
    "        path_img = quote(x[2])\n",
    "        jupyter_path = \"./empresas/img/\"+idn+\".png\"\n",
    "        im = Image.open(jupyter_path)\n",
    "        width, height = im.size\n",
    "        width = int(width*48/height)\n",
    "    \n",
    "    content  = \"createItem(\"+ quote(name_empresa) +\",\"+ path_img +\",\"+ str(width) +\",\"+ links + \")\"\n",
    "    \n",
    "    res = \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start \n",
    "        \n",
    "    res += \"}\"\n",
    "    return res\n",
    "\n",
    "def try_create(x):\n",
    "    try:\n",
    "        return crear_evento(x)\n",
    "        # If exception is raised, no return\n",
    "    except Exception as exc:\n",
    "        print('ERROR '+ x[0])\n",
    "\n",
    "print(\"event:\",crear_evento(df.iloc[4]))\n",
    "print(handled_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "#Necesito vaciar la lsita de repetidos antes de procesar todo el df\n",
    "handled_repeats = []\n",
    "\n",
    "!cp ./empresas/trabajos_appendable.js ./empresas/trabajos_appendable_backup.js\n",
    "!cp ./empresas/trabajos.js ./empresas/trabajos_backup.js\n",
    "f = open(\"./empresas/trabajos_appendable.js\", \"a\")\n",
    "#f.write(start_line)\n",
    "#f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "df_copy = df.copy()\n",
    "cosas = df_copy.apply(try_create,axis=1)\n",
    "cosas = cosas.dropna() #Drop lines that threw exception (repeated enterprise event)\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #Write up to second-to-last event in file\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./empresas/trabajos_appendable.js\" \"./empresas/trabajos.js\"\n",
    "\n",
    "f2 = open(\"./empresas/trabajos.js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./empresas/trabajos_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empresas que ya estaban presentes en la linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Lo que habría que hacer acá es copiar trabajos_appendable.js y reimprimirla modificando las lineas que corresponden.\n",
    "df2 = df[df['present']=='Si'].count()[0]\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
