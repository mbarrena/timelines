{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import requests\n",
    "import unicodedata\n",
    "from PIL import Image\n",
    "\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizar_nombre(name):\n",
    "    return strip_accents((name.replace(\" \", \"_\").replace(\"(\",\"\").replace(\")\",\"\")).lower())\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "# precondición: el campo imagen no es NaN\n",
    "def obtener_url_img(y):\n",
    "    url = y[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "def obtenerlink(y):\n",
    "    #print(y)\n",
    "    url = y[5].split('\":\"')[1]\n",
    "    url2 = url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "def quote(str):\n",
    "    return '\"'+str+'\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPRESAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Timeglider csv\n",
    "df = pd.read_csv(\"./linea_tiempo.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['startdate', ' enddate', ' title', ' description', ' importance',\n",
      "       ' link', ' icon', ' image', ' date_display', ' low threshold',\n",
      "       ' high threshold', ' y_position'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>Ledesma</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=199_...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://upload.wikimedia.org/wikipedia...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>Ferrocarril del Oeste</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=0B8E...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1865-07-02 00:28:00</td>\n",
       "      <td>1865-07-02 00:28:00</td>\n",
       "      <td>Semino</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1gSn...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://s3.amazonaws.com/timeglider_us...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1876-07-01 22:39:00</td>\n",
       "      <td>1876-07-01 22:39:00</td>\n",
       "      <td>Laboratorios Casasco</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1YlL...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://www.colfarma.info/colfarma/wp-...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1877-04-10 00:50:00</td>\n",
       "      <td>1877-04-10 00:50:00</td>\n",
       "      <td>CGFSA</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1aLF...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://static.wixstatic.com/media/89b...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             startdate              enddate                  title  \\\n",
       "0  1830-12-31 18:14:00  1830-12-31 18:14:00                Ledesma   \n",
       "1  1857-08-27 14:08:00  1857-08-27 14:08:00  Ferrocarril del Oeste   \n",
       "2  1865-07-02 00:28:00  1865-07-02 00:28:00                 Semino   \n",
       "3  1876-07-01 22:39:00  1876-07-01 22:39:00   Laboratorios Casasco   \n",
       "4  1877-04-10 00:50:00  1877-04-10 00:50:00                  CGFSA   \n",
       "\n",
       "   description   importance  \\\n",
       "0      <p></p>           50   \n",
       "1      <p></p>           50   \n",
       "2      <p></p>           50   \n",
       "3      <p></p>           50   \n",
       "4      <p></p>           50   \n",
       "\n",
       "                                                link  \\\n",
       "0  [{\"url\":\"https://drive.google.com/open?id=199_...   \n",
       "1  [{\"url\":\"https://drive.google.com/open?id=0B8E...   \n",
       "2  [{\"url\":\"https://drive.google.com/open?id=1gSn...   \n",
       "3  [{\"url\":\"https://drive.google.com/open?id=1YlL...   \n",
       "4  [{\"url\":\"https://drive.google.com/open?id=1aLF...   \n",
       "\n",
       "                       icon  \\\n",
       "0  shapes/triangle_gray.png   \n",
       "1  shapes/triangle_gray.png   \n",
       "2  shapes/triangle_gray.png   \n",
       "3  shapes/triangle_gray.png   \n",
       "4  shapes/triangle_gray.png   \n",
       "\n",
       "                                               image  date_display  \\\n",
       "0  {\"src\":\"https://upload.wikimedia.org/wikipedia...            da   \n",
       "1                                                NaN            da   \n",
       "2  {\"src\":\"https://s3.amazonaws.com/timeglider_us...            da   \n",
       "3  {\"src\":\"https://www.colfarma.info/colfarma/wp-...            da   \n",
       "4  {\"src\":\"https://static.wixstatic.com/media/89b...            da   \n",
       "\n",
       "    low threshold   high threshold   y_position  \n",
       "0               1              100            0  \n",
       "1               1              100            0  \n",
       "2               1              100            0  \n",
       "3               1              100            0  \n",
       "4               1              100            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually filtering some data and fixing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ledesma' 'Ferrocarril del Oeste' 'Semino' 'Laboratorios Casasco' 'CGFSA'\n",
      " 'Aguila Saint' 'Hesperdina' 'Rigolleau'\n",
      " 'Fábrica Argentina de Alpargatas (2)'\n",
      " 'Fábrica Argentina de Alpargatas (1)' 'Frigorífico Anglo' 'Bunge y Born'\n",
      " 'Alpargatas (1)' 'Alpargatas (2)' 'Quilmes' 'La Matrona' 'Grimoldi'\n",
      " 'Cerro Negro' 'British American Tabacco' 'Pirelli (2)' 'Pirelli (1)'\n",
      " 'La Martona' 'Molinos Río de la Plata S.A.' 'La Cantábrica'\n",
      " 'Molinos Río de la Plata' 'Banco Galicia' 'Swift' 'Frávega' 'Ferrum (2)'\n",
      " 'Bayer Argentina S.A.' 'Ferrum (1)' 'SIAM (2)' 'SIAM (1)' 'Terrabusi'\n",
      " 'Cerveza Schneider' 'Obras Sanitarias de la Nación' 'BGH' 'FORD'\n",
      " 'Shell (2)' 'Shell (1)' 'Firestone' 'Goodyear' 'Kodak' 'Longvie' 'FIAT'\n",
      " 'Roemmers' 'YPF (3)' 'YPF (2)' 'YPF (1)'\n",
      " 'Frigorífico Lisandro de la Torre (1)'\n",
      " 'Frigorífico Lisandro de la Torre (2)' 'Estancias Las Marías, Taragüi'\n",
      " 'General Motors (1)' 'General Motors (2)' 'Felfort (2)' 'Felfort (1)'\n",
      " 'Loma Negra' 'Milkaut' 'Colgate - Palmolive' 'La Serenísima (1)'\n",
      " 'La serenísima (2)' 'La serenísima (3)' 'Johnson &amp; Johnson'\n",
      " 'Molina Cañuelas' 'PHILCO' 'Bagó' 'Phillips' 'SanCor' 'Fernet Branca'\n",
      " 'Dirección General de Fabricaciones Militares' 'Acindar' 'Coca-Cola'\n",
      " 'Altos Hornos Zapla' 'Guaymallén' 'Techint' 'Entel (2)' 'Gas del Estado'\n",
      " 'Entel (1)' 'Havanna (1)' 'Havanna (2)' 'Aerolíneas Argentinas (3)'\n",
      " 'Aerolíneas Argentinas (1)' 'Aerolineas Argentinas (2)' 'Tenaris'\n",
      " 'Arcor (2)' 'Arcor (1)' 'Arcor (3)' 'Arcor (4)' 'Televisión Pública'\n",
      " 'Embalse de Río Hondo' 'Astillero Río Santiago'\n",
      " 'Industrias Kaiser Argentina S.A.' 'Correo OCA' 'Flecha Bus' 'Oslé'\n",
      " 'Peugeot' 'ELMA' 'Canal 13' 'Telefe' 'LOréal' 'Chocón-Cerros colorados'\n",
      " 'Central Hidroeléctrica Pueblo Viejo (1)'\n",
      " 'Central Hidroeléctrica Pueblo Viejo (2)' 'Don Satur'\n",
      " 'Banco Santander Río' 'Freddo' 'Corven' 'ALUAR' 'Correo Argentino'\n",
      " 'Sheraton' 'Represa el Chocón' 'Karavell' 'Represa Yacyretá'\n",
      " 'Central Nuclear Atucha' 'Pumper Nic' 'Renault Argentina (2)'\n",
      " 'Renault Argentina (1)' 'Banco Macro' 'Cerámica Fasinpát (ex Zanón)'\n",
      " 'Zanón (2)' 'Día' 'Cablevisión' 'Banco Comafi'\n",
      " 'Central Hidroeléctrica Río Grande' 'Arcos Dorados S.A.' 'Coto' 'Movicom'\n",
      " 'Telecentro' 'Edenor' 'UNSAM' 'Motomel' 'Pepsico Argentina' 'FARMACITY'\n",
      " 'Ampliación Av. General Paz' 'Despegar' 'Mercado Libre' 'Hilton' 'Grido'\n",
      " 'Crocs' 'CTI Móvil - Claro Argentina'\n",
      " 'Paseo Bajo nivel de Villa Ballester']\n"
     ]
    }
   ],
   "source": [
    "print(df[' title'].unique())\n",
    "alpargatas=[\"Fábrica Argentina de Alpargatas\",\"Alpargatas\"] #multiple, deberían ser en 1883 todos # pasa a ser Alpargatas\n",
    "ferrum=[\"Ferrum\"]\n",
    "siam=[\"SIAM\"]\n",
    "pirelli=[\"Pirelli\"]\n",
    "shell = [\"Shell\"]\n",
    "ypf = [\"YPF\"]\n",
    "torre = [\"Frigorífico Lisandro de la Torre\"]\n",
    "gm = [\"General Motors\"]\n",
    "felfort = [\"Felfort\"]\n",
    "sere=[\"La Serenísima\"]\n",
    "entel = [\"Entel\"]\n",
    "havanna = [\"Havanna\"]\n",
    "aa = [\"Aerolíneas Argentinas\"]\n",
    "arcor = [\"Arcor\"]\n",
    "pv = [\"Central Hidroeléctrica Pueblo Viejo\"]\n",
    "renault = [\"Renault Argentina\"]\n",
    "zanon = [\"Cerámica Fasinpát (ex Zanón)\", \"Zanón\"] #pasa a ser Zanón\n",
    "casasco = [\"Laboratorios Casasco\"]\n",
    "milkaut = [\"Milkaut\"]\n",
    "banco_macro = [\"Banco Macro\"]\n",
    "multiples = [\"Alpargatas\",\"Ferrum\",\"SIAM\",\"Pirelli\",\"Shell\",\"YPF\",\"Frigorífico Lisandro de la Torre\",\"General Motors\",\"Felfort\",\"La Serenísima\",\"Entel\",\"Havanna\",\"Aerolíneas Argentinas\",\"Arcor\",\"Central Hidroeléctrica Pueblo Viejo\",\"Renault Argentina\",\"Zanón\",\"Laboratorios Casasco\",\"Milkaut\",\"Banco Macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALUAR', 'Acindar', 'Aerolíneas Argentinas', 'Aguila Saint', 'Alpargatas', 'Altos Hornos Zapla', 'Ampliación Av. General Paz', 'Arcor', 'Arcos Dorados S.A.', 'Astillero Río Santiago', 'BGH', 'Bagó', 'Banco Comafi', 'Banco Galicia', 'Banco Macro', 'Banco Santander Río', 'Bayer Argentina S.A.', 'British American Tabacco', 'Bunge y Born', 'CGFSA', 'CTI Móvil - Claro Argentina', 'Cablevisión', 'Canal 13', 'Central Hidroeléctrica Pueblo Viejo', 'Central Hidroeléctrica Río Grande', 'Central Nuclear Atucha', 'Cerro Negro', 'Cerveza Schneider', 'Cerámica Fasinpát (ex Zanón)', 'Chocón-Cerros colorados', 'Coca-Cola', 'Colgate - Palmolive', 'Correo Argentino', 'Correo OCA', 'Corven', 'Coto', 'Crocs', 'Despegar', 'Dirección General de Fabricaciones Militares', 'Don Satur', 'Día', 'ELMA', 'Edenor', 'Embalse de Río Hondo', 'Entel', 'Estancias Las Marías, Taragüi', 'FARMACITY', 'FIAT', 'FORD', 'Felfort', 'Fernet Branca', 'Ferrocarril del Oeste', 'Ferrum', 'Firestone', 'Flecha Bus', 'Freddo', 'Frigorífico Anglo', 'Frigorífico Lisandro de la Torre', 'Frávega', 'Fábrica Argentina de Alpargatas', 'Gas del Estado', 'General Motors', 'Goodyear', 'Grido', 'Grimoldi', 'Guaymallén', 'Havanna', 'Hesperdina', 'Hilton', 'Industrias Kaiser Argentina S.A.', 'Johnson &amp; Johnson', 'Karavell', 'Kodak', 'LOréal', 'La Cantábrica', 'La Martona', 'La Matrona', 'La Serenísima', 'Laboratorios Casasco', 'Ledesma', 'Loma Negra', 'Longvie', 'Mercado Libre', 'Milkaut', 'Molina Cañuelas', 'Molinos Río de la Plata', 'Molinos Río de la Plata S.A.', 'Motomel', 'Movicom', 'Obras Sanitarias de la Nación', 'Oslé', 'PHILCO', 'Paseo Bajo nivel de Villa Ballester', 'Pepsico Argentina', 'Peugeot', 'Phillips', 'Pirelli', 'Pumper Nic', 'Quilmes', 'Renault Argentina', 'Represa Yacyretá', 'Represa el Chocón', 'Rigolleau', 'Roemmers', 'SIAM', 'SanCor', 'Semino', 'Shell', 'Sheraton', 'Swift', 'Techint', 'Telecentro', 'Telefe', 'Televisión Pública', 'Tenaris', 'Terrabusi', 'UNSAM', 'YPF']\n"
     ]
    }
   ],
   "source": [
    "lst = ['Ledesma','Ferrocarril del Oeste','Semino','Laboratorios Casasco','CGFSA','Aguila Saint', 'Hesperdina', 'Rigolleau','Fábrica Argentina de Alpargatas', 'Frigorífico Anglo', 'Bunge y Born','Alpargatas', 'Quilmes', 'La Matrona', 'Grimoldi','Cerro Negro', 'British American Tabacco', 'Pirelli','La Martona', 'Molinos Río de la Plata S.A.', 'La Cantábrica','Molinos Río de la Plata', 'Banco Galicia', 'Swift', 'Frávega','Bayer Argentina S.A.', 'Ferrum', 'SIAM', 'Terrabusi','Cerveza Schneider', 'Obras Sanitarias de la Nación', 'BGH', 'FORD', 'Shell', 'Firestone', 'Goodyear', 'Kodak', 'Longvie', 'FIAT','Roemmers', 'YPF','Frigorífico Lisandro de la Torre', 'Estancias Las Marías, Taragüi','General Motors', 'Felfort','Loma Negra', 'Milkaut', 'Colgate - Palmolive', 'La Serenísima', 'Johnson &amp; Johnson','Molina Cañuelas', 'PHILCO', 'Bagó', 'Phillips', 'SanCor', 'Fernet Branca','Dirección General de Fabricaciones Militares', 'Acindar', 'Coca-Cola','Altos Hornos Zapla', 'Guaymallén', 'Techint', 'Gas del Estado','Entel', 'Havanna','Aerolíneas Argentinas', 'Tenaris', 'Arcor', 'Televisión Pública','Embalse de Río Hondo', 'Astillero Río Santiago','Industrias Kaiser Argentina S.A.', 'Correo OCA', 'Flecha Bus', 'Oslé','Peugeot', 'ELMA', 'Canal 13', 'Telefe', 'LOréal', 'Chocón-Cerros colorados','Central Hidroeléctrica Pueblo Viejo', 'Don Satur','Banco Santander Río', 'Freddo', 'Corven', 'ALUAR', 'Correo Argentino','Sheraton', 'Represa el Chocón', 'Karavell', 'Represa Yacyretá','Central Nuclear Atucha', 'Pumper Nic','Renault Argentina', 'Banco Macro', 'Cerámica Fasinpát (ex Zanón)', 'Día', 'Cablevisión', 'Banco Comafi','Central Hidroeléctrica Río Grande', 'Arcos Dorados S.A.', 'Coto', 'Movicom','Telecentro', 'Edenor', 'UNSAM', 'Motomel', 'Pepsico Argentina', 'FARMACITY','Ampliación Av. General Paz', 'Despegar', 'Mercado Libre', 'Hilton', 'Grido','Crocs', 'CTI Móvil - Claro Argentina','Paseo Bajo nivel de Villa Ballester'\n",
    "]\n",
    "lst.sort()\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes this cell has to be ran twice\n",
    "filtro_alpargatas = (df[' title'].str.contains(alpargatas[0])) | (df[' title'].str.contains(alpargatas[1]))\n",
    "#df.loc[filtro_alpargatas,' title'] = \"Alpargatas\"\n",
    "df[filtro_alpargatas].head()\n",
    "for i in range(df[filtro_alpargatas].count()[0]):\n",
    "    df.loc[filtro_alpargatas,' title'].iloc[i] = \"Alpargatas (\"+str(i)+\")\"\n",
    "#df.loc[9,' title'] = \"Alpargatas (2)\"\n",
    "#df.loc[12,' title'] = \"Alpargatas (3)\"\n",
    "#df.loc[13,' title'] = \"Alpargatas (4)\"\n",
    "\n",
    "filtro_zanon = (df[' title'].str.contains(zanon[0])) | (df[' title'].str.contains(zanon[1]))\n",
    "df[filtro_zanon].head()\n",
    "for i in range(df[filtro_zanon].count()[0]):\n",
    "    df.loc[filtro_zanon,' title'].iloc[i] = \"Zanón (\"+str(i)+\")\"\n",
    "#df.loc[118,' title'] = \"Zanón (1)\"\n",
    "#df.loc[199,' title'] = \"Zanón (2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events based on timeglider csv (migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>Banco Macro (1)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=10Zg...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://s3.amazonaws.com/timeglider_us...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>Banco Macro (2)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=165G...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>0</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               startdate              enddate            title  description  \\\n",
       "130  1978-09-04 11:53:00  1978-09-04 11:53:00  Banco Macro (1)      <p></p>   \n",
       "131  1978-09-04 23:57:00  1978-09-04 23:57:00  Banco Macro (2)      <p></p>   \n",
       "\n",
       "      importance                                               link  \\\n",
       "130           50  [{\"url\":\"https://drive.google.com/open?id=10Zg...   \n",
       "131           50  [{\"url\":\"https://drive.google.com/open?id=165G...   \n",
       "\n",
       "                         icon  \\\n",
       "130  shapes/triangle_gray.png   \n",
       "131  shapes/triangle_gray.png   \n",
       "\n",
       "                                                 image  date_display  \\\n",
       "130  {\"src\":\"https://s3.amazonaws.com/timeglider_us...            da   \n",
       "131                                                  0            da   \n",
       "\n",
       "      low threshold   high threshold   y_position  \n",
       "130               1              100            0  \n",
       "131               1              100            0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscamos crear algo de esta pinta:\n",
    "'''\n",
    "var items = new vis.DataSet([\n",
    "{id: 1, content: 'item 1', start: '2014-04-20'},\n",
    "{id: 2, content: 'item 2', start: '2014-04-14'},\n",
    "{id: 3, content: 'item 3', start: '2014-04-18'},\n",
    "{id: 4, content: 'item 4', start: '2014-04-16', end: '2014-04-19'},\n",
    "{id: 5, content:  createItem(\"item 5\",'./img/swift.jpg',[\"https://makobot-prod.github.io/timelines/\",\"blabla\"])  , start: '2014-04-25'},\n",
    "{id: 6, content: 'item 6', start: '2014-04-27', type: 'point'}\n",
    "]);\n",
    "'''\n",
    "df[' image'] = df[' image'].fillna(0)\n",
    "### PARECERÍA ESTAR ANDANDO\n",
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[2])\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    name_empresa = x[2]\n",
    "    \n",
    "    if(multiples.count(x[2][:-4])==0):\n",
    "        links = \"[\"+ quote(obtenerlink(x)) + \"]\" #crear esta func\n",
    "    else:\n",
    "        #tengo multiples trabajos de esta empresa\n",
    "        #en algun lado me tengo que guardar los múltiples\n",
    "        name_empresa = x[2][:-4]\n",
    "        idn = idn[:-2]\n",
    "        filtro = df[' title'].str.contains(x[2][:-4])\n",
    "        df_links = df[filtro]\n",
    "        links = \"[\"\n",
    "        df_links = df_links.apply(obtenerlink,axis=1)\n",
    "        for item in df_links.iteritems():\n",
    "            url = item[1]\n",
    "            links += quote(url) + \",\"\n",
    "        links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    if(x[7]!= 0):\n",
    "        path_img = quote('./img/'+idn+'.png')\n",
    "        im = Image.open('./timelines/img/'+idn+'.png')\n",
    "        width, height = im.size\n",
    "        width = int(width*48/height)\n",
    "    \n",
    "    content  = \"createItem(\"+ quote(name_empresa) +\",\"+ path_img +\",\"+ str(width) +\",\"+ links + \")\"\n",
    "    \n",
    "    return \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start + \"}\"\n",
    "            \n",
    "#crear_evento(df.loc[118])\n",
    "#df.loc[118]\n",
    "filtro = df[' title'].str.contains(\"Banco Macro\")\n",
    "df[filtro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "df_sin_repes = df.copy()\n",
    "filtro_repes = (df[' title'].str.contains(\"\\(\")) & (~(df[' title'].str.contains(\"\\(1\\)\")))\n",
    "df_sin_repes = df_sin_repes[~filtro_repes]\n",
    "\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "#f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "cosas = df_sin_repes.apply(crear_evento,axis=1)\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./timelines/empresas/trabajos_appendable.js\" \"./timelines/trabajos.js\"\n",
    "\n",
    "f2 = open(\"./timelines/empresas/trabajos.js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizer (OVERWRITES IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBSOLETE: images are not that heavy and look better without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded /tmp/magick-3689dVLyjnH2RKVf. Dimensions: 560 x 210  (with alpha). Format: lossless. Now saving...\n",
      "Saved file /tmp/magick-3689r4TsGY9Aa3Al\n",
      "convert-im6.q16: improper image header `./timelines/img/coto.png' @ error/png.c/ReadPNGImage/3954.\n",
      "convert-im6.q16: improper image header `./timelines/img/sheraton.png' @ error/png.c/ReadPNGImage/3954.\n"
     ]
    }
   ],
   "source": [
    "#!convert \"./timelines/empresas/img/*.png\" -filter Lanczos -resize x48 -sharpen 0x.5 -set filename:base \"%[basename]\" \"./timelines/empresas/img/%[filename:base].png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete _1 from filename for images that end in _1\n",
    "#!for file in `find . -name '*_1.png'` ; do mv \"$file\" \"${file%_1.png}.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline event images downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\", \"local-filename.jpg\")\n",
    "# Quiero hacer una función que, dada una fila, me baje la imagen\n",
    "df_img=df.copy()\n",
    "df_img.dropna(subset=[' image'], inplace=True) \n",
    "falladas=[]\n",
    "assert(False)\n",
    "#path = \"./img_originales/\"\n",
    "def image_download(x):\n",
    "    empresa=sanitizar_nombre(x[2])\n",
    "    # donde x es una serie de Pandas\n",
    "    url = x[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    print(url2)\n",
    "    try:\n",
    "        #response = requests.get(url2)\n",
    "        print(\"Downloading img for\",empresa)\n",
    "        urllib.request.urlretrieve(url2, path + empresa.lower() + \".png\")\n",
    "    except Exception as exc:\n",
    "        print('[!!!] {err}'.format(err=exc),\"retrieving img for\", empresa ,\"aborted\")\n",
    "        falladas.append(empresa)\n",
    "\n",
    "for index, row in df_img.iterrows():\n",
    "    print(index)\n",
    "    image_download(df_img.loc[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cgfsa', 'correo_oca', 'don_satur', 'sheraton', 'arcos_dorados_s.a.', 'telecentro']\n"
     ]
    }
   ],
   "source": [
    "print(falladas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not np.isnan(df.loc[1][7].isnull()):\n",
    "    print(\"Not a nan\")\n",
    "    print(df.loc[1][7])\n",
    "    urllib.request.urlretrieve(df.loc[1][7], path+df.loc[1][2].lower()+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTORIC EVENTS TIMELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./7unidad/7unidad.csv\",index_col=False)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "logo_info = \"www.cooperacion2005.es\"\n",
    "logo_tour = \"guejarsierra.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>lowthreshold</th>\n",
       "      <th>highthreshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1966-01-01 22:10:00</td>\n",
       "      <td>1966-01-01 22:10:00</td>\n",
       "      <td>Déc.1960: debilitamiento del dólar y de las re...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1966-01-01 22:10:00</td>\n",
       "      <td>1966-01-01 22:10:00</td>\n",
       "      <td>Entre 1965-66: cambio reservas francesas de dó...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1966-06-28 18:29:00</td>\n",
       "      <td>1966-06-28 18:29:00</td>\n",
       "      <td>28-06-1966: &amp;#34;Revolución Argentina&amp;#34;</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>75</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1tn8...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966-06-29 12:00:00</td>\n",
       "      <td>1966-06-29 12:00:00</td>\n",
       "      <td>29-06-1966: Ministro de Economía J. Salimei (h...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=1OTO...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1966-06-29 18:29:00</td>\n",
       "      <td>1966-06-29 18:29:00</td>\n",
       "      <td>29-06-1966: asume la presidencia Gral. Onganía...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             startdate              enddate  \\\n",
       "0  1966-01-01 22:10:00  1966-01-01 22:10:00   \n",
       "1  1966-01-01 22:10:00  1966-01-01 22:10:00   \n",
       "2  1966-06-28 18:29:00  1966-06-28 18:29:00   \n",
       "3  1966-06-29 12:00:00  1966-06-29 12:00:00   \n",
       "4  1966-06-29 18:29:00  1966-06-29 18:29:00   \n",
       "\n",
       "                                               title description  importance  \\\n",
       "0  Déc.1960: debilitamiento del dólar y de las re...     <p></p>          50   \n",
       "1  Entre 1965-66: cambio reservas francesas de dó...     <p></p>          50   \n",
       "2         28-06-1966: &#34;Revolución Argentina&#34;     <p></p>          75   \n",
       "3  29-06-1966: Ministro de Economía J. Salimei (h...     <p></p>          60   \n",
       "4  29-06-1966: asume la presidencia Gral. Onganía...     <p></p>          60   \n",
       "\n",
       "                                                link  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [{\"url\":\"https://drive.google.com/open?id=1tn8...   \n",
       "3  [{\"url\":\"https://drive.google.com/open?id=1OTO...   \n",
       "4                                                NaN   \n",
       "\n",
       "                       icon  \\\n",
       "0  shapes/triangle_gray.png   \n",
       "1  shapes/triangle_gray.png   \n",
       "2  shapes/triangle_gray.png   \n",
       "3  shapes/triangle_gray.png   \n",
       "4  shapes/triangle_gray.png   \n",
       "\n",
       "                                               image date_display  \\\n",
       "0                                                NaN           da   \n",
       "1                                                NaN           da   \n",
       "2  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "3  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "4                                                NaN           da   \n",
       "\n",
       "   lowthreshold  highthreshold  y_position  \n",
       "0             1            100           0  \n",
       "1             1            100           0  \n",
       "2             1            100           0  \n",
       "3             1            100           0  \n",
       "4             1            100           0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turismo\n"
     ]
    }
   ],
   "source": [
    "# Identify type of timeline event (general information (logo_info) vs tourist information (logo_tour))\n",
    "def find_type(event):\n",
    "    if(not pd.isnull(event[7])):\n",
    "        #not a NaN\n",
    "        if(event[7][15:37]==logo_info):\n",
    "            return \"informacion\"\n",
    "        elif(event[7][15:31]==logo_tour):\n",
    "            return \"turismo\"\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(find_type(df.iloc[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrate events from Timeglider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29-07-1966:_la_noche_']\n"
     ]
    }
   ],
   "source": [
    "# First, we must identify possible repeated events\n",
    "\n",
    "def get_name(x):\n",
    "    return sanitizar_nombre(x[2])[:21]\n",
    "\n",
    "names = df.apply(get_name,axis=1)\n",
    "seen = set()\n",
    "check_repeats = []\n",
    "for x in names:\n",
    "    if x not in seen:\n",
    "        seen.add(x)\n",
    "    else:\n",
    "        check_repeats.append(x)\n",
    "handled_repeats=[]\n",
    "print(check_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: {id: \"1966:_&#34;revolucion\", content: \"1966: \\\"Revolución Cultural Proletaria\\\" en China (Mao Tse-Tung)\", image:\"../img/informacion.svg\", link:\"https://drive.google.com/file/d/1VlX5mQ32ZYRFTuMatb1xLTFz4p84t1pH/view\", start: \"1966-07-01\"}\n",
      "['29-07-1966:_la_noche_']\n"
     ]
    }
   ],
   "source": [
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[2])[:21]\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    end = \"0\"\n",
    "    if(x[0][:-9] != x[1][:-9]):\n",
    "        end = quote(x[1][:-9])\n",
    "    \n",
    "    name_event = x[2].replace(\"&#34;\", '\\\\\"')\n",
    "    count_links = 0\n",
    "    \n",
    "    if(not pd.isnull(x[5])):\n",
    "        if(check_repeats.count(idn)==0):\n",
    "            #Event is not repeated\n",
    "            count_links = 1\n",
    "            links = \"[\"+ quote(obtenerlink(x)) + \"]\" \n",
    "        else:\n",
    "            if(handled_repeats.count(idn)!=0):\n",
    "                raise Exception(\"Event already created\") \n",
    "            handled_repeats.append(idn) #we only want one event with all the data\n",
    "            count_links = 2 #more than 1 link = more than 1 work on same event\n",
    "            filtro = df['title'].str.contains(x[2][:21])\n",
    "            df_links = df[filtro]\n",
    "            links = \"[\"\n",
    "            df_links = df_links.apply(obtenerlink,axis=1)\n",
    "            for item in df_links.iteritems():\n",
    "                url = item[1]\n",
    "                links += quote(url) + \",\"\n",
    "            links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    else:\n",
    "        links = \"[\"+\"]\"\n",
    "    \n",
    "    img = find_type(x)\n",
    "    content  = quote(name_event) \n",
    "    \n",
    "    if(img!= 0):\n",
    "        #if there is an image, include image\n",
    "        path_img = quote('../img/'+img+'.svg')\n",
    "        content += \", image:\"+ path_img \n",
    "        \n",
    "    if(count_links>1):\n",
    "        #if there is multiple links, pass list of links\n",
    "        content += \", links:\" + links\n",
    "    elif(count_links==1):\n",
    "        #if there is only one link, pass single link\n",
    "        content += \", link:\" + links[1:][:-1]\n",
    "    \n",
    "    res = \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start \n",
    "    if(end!=\"0\"):\n",
    "        res += \", end: \" + end\n",
    "        \n",
    "    res += \"}\"\n",
    "    return res\n",
    "\n",
    "def try_create(x):\n",
    "    try:\n",
    "        return crear_evento(x)\n",
    "        # If exception is raised, no return\n",
    "    except Exception as exc:\n",
    "        print('[!!!] Evento repetido:',x[2])\n",
    "\n",
    "print(\"event:\",crear_evento(df.iloc[5]))\n",
    "print(handled_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "[!!!] Evento repetido: 29-07-1966: la Noche de los Bastones Largos BIS\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "unit = \"7unidad\"\n",
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "handled_repeats = []\n",
    "\n",
    "f = open(\"./\"+unit+\"/\"+unit+\"_appendable.js\", \"a\")\n",
    "f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "df_copy = df.copy()\n",
    "cosas = df_copy.apply(try_create,axis=1)\n",
    "cosas = cosas.dropna()\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./{unit}/{unit}_appendable.js\" \"./{unit}/{unit}.js\"\n",
    "\n",
    "f2 = open(\"./\"+unit+\"/\"+unit+\".js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./\"+unit+\"/\"+unit+\"_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
