{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import requests\n",
    "import unicodedata\n",
    "from PIL import Image\n",
    "\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizar_nombre(name):\n",
    "    return strip_accents((name.replace(\" \", \"_\").replace(\"(\",\"\").replace(\")\",\"\")).lower())\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "# precondición: el campo imagen no es NaN\n",
    "def obtener_url_img(y):\n",
    "    url = y[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "# RECIBE FILA DEL DATAFRAME\n",
    "def obtenerlink(y):\n",
    "    #print(y)\n",
    "    url = y[5].split('\":\"')[1]\n",
    "    url2 = url2 = url.split(\",\")[0][:-1]\n",
    "    return url2\n",
    "\n",
    "def quote(str):\n",
    "    return '\"'+str+'\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPRESAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Timeglider csv\n",
    "df = pd.read_csv(\"./timelines/linea_tiempo.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['startdate', ' enddate', ' title', ' description', ' importance',\n",
      "       ' link', ' icon', ' image', ' date_display', ' low threshold',\n",
      "       ' high threshold', ' y_position'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>1830-12-31 18:14:00</td>\n",
       "      <td>Ledesma</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=199_...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://upload.wikimedia.org/wikipedia...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1838-04-19 07:51:00</td>\n",
       "      <td>1838-04-19 07:51:00</td>\n",
       "      <td>Delfino</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"http://drive.google.com/uc?export=vie...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://raw.githubusercontent.com/mako...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1847-10-12 16:02:00</td>\n",
       "      <td>1847-10-12 16:02:00</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://raw.githubusercontent.com/mak...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://raw.githubusercontent.com/mako...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>1857-08-27 14:08:00</td>\n",
       "      <td>Ferrocarril del Oeste</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=0B8E...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1863-01-01 12:02:00</td>\n",
       "      <td>1863-01-01 12:02:00</td>\n",
       "      <td>Ferrocarriles Argentinos</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"http://drive.google.com/uc?export=vie...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://raw.githubusercontent.com/mako...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             startdate              enddate                     title  \\\n",
       "0  1830-12-31 18:14:00  1830-12-31 18:14:00                   Ledesma   \n",
       "1  1838-04-19 07:51:00  1838-04-19 07:51:00                   Delfino   \n",
       "2  1847-10-12 16:02:00  1847-10-12 16:02:00                   Siemens   \n",
       "3  1857-08-27 14:08:00  1857-08-27 14:08:00     Ferrocarril del Oeste   \n",
       "4  1863-01-01 12:02:00  1863-01-01 12:02:00  Ferrocarriles Argentinos   \n",
       "\n",
       "   description   importance  \\\n",
       "0      <p></p>           50   \n",
       "1      <p></p>           50   \n",
       "2      <p></p>           50   \n",
       "3      <p></p>           50   \n",
       "4      <p></p>           50   \n",
       "\n",
       "                                                link  \\\n",
       "0  [{\"url\":\"https://drive.google.com/open?id=199_...   \n",
       "1  [{\"url\":\"http://drive.google.com/uc?export=vie...   \n",
       "2  [{\"url\":\"https://raw.githubusercontent.com/mak...   \n",
       "3  [{\"url\":\"https://drive.google.com/open?id=0B8E...   \n",
       "4  [{\"url\":\"http://drive.google.com/uc?export=vie...   \n",
       "\n",
       "                       icon  \\\n",
       "0  shapes/triangle_gray.png   \n",
       "1  shapes/triangle_gray.png   \n",
       "2  shapes/triangle_gray.png   \n",
       "3  shapes/triangle_gray.png   \n",
       "4  shapes/triangle_gray.png   \n",
       "\n",
       "                                               image  date_display  \\\n",
       "0  {\"src\":\"https://upload.wikimedia.org/wikipedia...            da   \n",
       "1  {\"src\":\"https://raw.githubusercontent.com/mako...            da   \n",
       "2  {\"src\":\"https://raw.githubusercontent.com/mako...            da   \n",
       "3                                                NaN            da   \n",
       "4  {\"src\":\"https://raw.githubusercontent.com/mako...            da   \n",
       "\n",
       "    low threshold   high threshold   y_position  \n",
       "0               1              100            0  \n",
       "1               1              100            0  \n",
       "2               1              100            0  \n",
       "3               1              100            0  \n",
       "4               1              100            0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually filtering some data and fixing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ledesma' 'Delfino' 'Siemens' 'Ferrocarril del Oeste'\n",
      " 'Ferrocarriles Argentinos' 'Semino' 'Laboratorios Casasco (2)'\n",
      " 'Laboratorios Casasco (1)' 'CGFSA' 'Aguila Saint' 'Hesperdina'\n",
      " 'Rigolleau' 'Fábrica Argentina de Alpargatas (2)'\n",
      " 'Fábrica Argentina de Alpargatas (1)' 'Frigorífico Anglo' 'Bunge y Born'\n",
      " 'Alpargatas (1)' 'Alpargatas (2)' 'Quilmes' 'La Matrona' 'Grimoldi'\n",
      " 'Cerro Negro' 'British American Tabacco' 'Pirelli (2)' 'Pirelli (1)'\n",
      " 'La Martona' 'Molinos Río de la Plata S.A.' 'La Cantábrica'\n",
      " 'Molinos Río de la Plata' 'Banco Galicia' 'Swift' 'Frávega' 'Ferrum (2)'\n",
      " 'Bayer Argentina S.A.' 'Ferrum (1)' 'SIAM (2)' 'SIAM (1)' 'Terrabusi'\n",
      " 'Cerveza Schneider' 'Obras Sanitarias de la Nación' 'BGH' 'FORD'\n",
      " 'Shell (2)' 'Shell (1)' 'Firestone' 'Goodyear' 'Kodak' 'Longvie' 'FIAT'\n",
      " 'Roemmers' 'YPF (3)' 'YPF (2)' 'YPF (1)'\n",
      " 'Frigorífico Lisandro de la Torre (1)'\n",
      " 'Frigorífico Lisandro de la Torre (2)' 'Taragüi, Estancias Las Marías'\n",
      " 'General Motors (1)' 'General Motors (2)' 'Felfort (2)' 'Felfort (1)'\n",
      " 'Loma Negra' 'Colgate - Palmolive' 'RCA Victor' 'La Serenísima (1)'\n",
      " 'La serenísima (2)' 'La serenísima (3)' 'Johnson &amp; Johnson'\n",
      " 'Molina Cañuelas' 'PHILCO' 'Bagó' 'Phillips' 'Milkaut (1)' 'Milkaut (2)'\n",
      " 'SanCor' 'Fernet Branca' 'Dirección General de Fabricaciones Militares'\n",
      " 'Acindar' 'Coca-Cola' 'Altos Hornos Zapla' 'Guaymallén' 'Techint'\n",
      " 'Entel (2)' 'Gas del Estado' 'Entel (1)' 'Havanna (1)' 'Havanna (2)'\n",
      " 'Pritty' 'Aerolíneas Argentinas (3)' 'Aerolíneas Argentinas (1)'\n",
      " 'Aerolineas Argentinas (2)' 'Tenaris' 'Arcor (2)' 'Arcor (1)' 'Arcor (3)'\n",
      " 'Arcor (4)' 'Televisión Pública' 'Embalse de Río Hondo'\n",
      " 'Astillero Río Santiago' 'Industrias Kaiser Argentina S.A.'\n",
      " 'Dique Frontal Río Hondo' 'Correo OCA' 'Flecha Bus' 'Carrefour' 'Oslé'\n",
      " 'Peugeot' 'ELMA' 'Canal 13' 'Telefe' 'Arcillex' 'LOréal'\n",
      " 'Chocón-Cerros colorados' 'Central Hidroeléctrica Pueblo Viejo (1)'\n",
      " 'Central Hidroeléctrica Pueblo Viejo (2)' 'Don Satur'\n",
      " 'Banco Santander Río' 'Freddo' 'Corven' 'ALUAR'\n",
      " 'Autopistas de Cacciatore' 'Correo Argentino' 'Sheraton'\n",
      " 'Represa el Chocón' 'Karavell' 'Represa Yacyretá'\n",
      " 'Central Nuclear Atucha' 'Pumper Nic' 'Metac' 'Renault Argentina (2)'\n",
      " 'Renault Argentina (1)' 'Banco Credicoop' 'Banco Macro (1)'\n",
      " 'Banco Macro (2)' 'Cerámica Fasinpát (ex Zanón)' 'Zanón (2)' 'Día'\n",
      " 'Cablevisión' 'Banco Comafi' 'Central Hidroeléctrica Río Grande'\n",
      " 'Arcos Dorados S.A.' 'Coto' 'Movicom' 'Telefónica' 'Telecentro' 'Edenor'\n",
      " 'UNSAM' 'Motomel' 'Pepsico Argentina' 'Toyota' 'FARMACITY'\n",
      " 'Ampliación Av. General Paz' 'Despegar' 'Mercado Libre' 'Hilton' 'Grido'\n",
      " 'Mostaza' 'Crocs' 'Pampa energía' 'Manaos' 'CTI Móvil - Claro Argentina'\n",
      " 'Paseo Bajo nivel de Villa Ballester']\n"
     ]
    }
   ],
   "source": [
    "print(df[' title'].unique())\n",
    "alpargatas=[\"Fábrica Argentina de Alpargatas\",\"Alpargatas\"] #multiple, deberían ser en 1883 todos # pasa a ser Alpargatas\n",
    "ferrum=[\"Ferrum\"]\n",
    "siam=[\"SIAM\"]\n",
    "pirelli=[\"Pirelli\"]\n",
    "shell = [\"Shell\"]\n",
    "ypf = [\"YPF\"]\n",
    "torre = [\"Frigorífico Lisandro de la Torre\"]\n",
    "gm = [\"General Motors\"]\n",
    "felfort = [\"Felfort\"]\n",
    "sere=[\"La Serenísima\"]\n",
    "entel = [\"Entel\"]\n",
    "havanna = [\"Havanna\"]\n",
    "aa = [\"Aerolíneas Argentinas\"]\n",
    "arcor = [\"Arcor\"]\n",
    "pv = [\"Central Hidroeléctrica Pueblo Viejo\"]\n",
    "renault = [\"Renault Argentina\"]\n",
    "zanon = [\"Cerámica Fasinpát (ex Zanón)\", \"Zanón\"] #pasa a ser Zanón\n",
    "casasco = [\"Laboratorios Casasco\"]\n",
    "milkaut = [\"Milkaut\"]\n",
    "banco_macro = [\"Banco Macro\"]\n",
    "multiples = [\"Alpargatas\",\"Ferrum\",\"SIAM\",\"Pirelli\",\"Shell\",\"YPF\",\"Frigorífico Lisandro de la Torre\",\"General Motors\",\"Felfort\",\"La Serenísima\",\"Entel\",\"Havanna\",\"Aerolíneas Argentinas\",\"Arcor\",\"Central Hidroeléctrica Pueblo Viejo\",\"Renault Argentina\",\"Zanón\",\"Laboratorios Casasco\",\"Milkaut\",\"Banco Macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes this cell has to be ran twice\n",
    "filtro_alpargatas = (df[' title'].str.contains(alpargatas[0])) | (df[' title'].str.contains(alpargatas[1]))\n",
    "#df.loc[filtro_alpargatas,' title'] = \"Alpargatas\"\n",
    "df[filtro_alpargatas].head()\n",
    "for i in range(df[filtro_alpargatas].count()[0]):\n",
    "    df.loc[filtro_alpargatas,' title'].iloc[i] = \"Alpargatas (\"+str(i)+\")\"\n",
    "#df.loc[9,' title'] = \"Alpargatas (2)\"\n",
    "#df.loc[12,' title'] = \"Alpargatas (3)\"\n",
    "#df.loc[13,' title'] = \"Alpargatas (4)\"\n",
    "\n",
    "filtro_zanon = (df[' title'].str.contains(zanon[0])) | (df[' title'].str.contains(zanon[1]))\n",
    "df[filtro_zanon].head()\n",
    "for i in range(df[filtro_zanon].count()[0]):\n",
    "    df.loc[filtro_zanon,' title'].iloc[i] = \"Zanón (\"+str(i)+\")\"\n",
    "#df.loc[118,' title'] = \"Zanón (1)\"\n",
    "#df.loc[199,' title'] = \"Zanón (2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create events based on timeglider csv (migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>low threshold</th>\n",
       "      <th>high threshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>1978-09-04 11:53:00</td>\n",
       "      <td>Banco Macro (1)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=10Zg...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"https://s3.amazonaws.com/timeglider_us...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>1978-09-04 23:57:00</td>\n",
       "      <td>Banco Macro (2)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>50</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/open?id=165G...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>0</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               startdate              enddate            title  description  \\\n",
       "130  1978-09-04 11:53:00  1978-09-04 11:53:00  Banco Macro (1)      <p></p>   \n",
       "131  1978-09-04 23:57:00  1978-09-04 23:57:00  Banco Macro (2)      <p></p>   \n",
       "\n",
       "      importance                                               link  \\\n",
       "130           50  [{\"url\":\"https://drive.google.com/open?id=10Zg...   \n",
       "131           50  [{\"url\":\"https://drive.google.com/open?id=165G...   \n",
       "\n",
       "                         icon  \\\n",
       "130  shapes/triangle_gray.png   \n",
       "131  shapes/triangle_gray.png   \n",
       "\n",
       "                                                 image  date_display  \\\n",
       "130  {\"src\":\"https://s3.amazonaws.com/timeglider_us...            da   \n",
       "131                                                  0            da   \n",
       "\n",
       "      low threshold   high threshold   y_position  \n",
       "130               1              100            0  \n",
       "131               1              100            0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscamos crear algo de esta pinta:\n",
    "'''\n",
    "var items = new vis.DataSet([\n",
    "{id: 1, content: 'item 1', start: '2014-04-20'},\n",
    "{id: 2, content: 'item 2', start: '2014-04-14'},\n",
    "{id: 3, content: 'item 3', start: '2014-04-18'},\n",
    "{id: 4, content: 'item 4', start: '2014-04-16', end: '2014-04-19'},\n",
    "{id: 5, content:  createItem(\"item 5\",'./img/swift.jpg',[\"https://makobot-prod.github.io/timelines/\",\"blabla\"])  , start: '2014-04-25'},\n",
    "{id: 6, content: 'item 6', start: '2014-04-27', type: 'point'}\n",
    "]);\n",
    "'''\n",
    "df[' image'] = df[' image'].fillna(0)\n",
    "### PARECERÍA ESTAR ANDANDO\n",
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[2])\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    name_empresa = x[2]\n",
    "    \n",
    "    if(multiples.count(x[2][:-4])==0):\n",
    "        links = \"[\"+ quote(obtenerlink(x)) + \"]\" #crear esta func\n",
    "    else:\n",
    "        #tengo multiples trabajos de esta empresa\n",
    "        #se podría manejar arriba con un for supongo? en algun lado me tengo que guardar los múltiples\n",
    "        name_empresa = x[2][:-4]\n",
    "        idn = idn[:-2]\n",
    "        filtro = df[' title'].str.contains(x[2][:-4])\n",
    "        df_links = df[filtro]\n",
    "        links = \"[\"\n",
    "        df_links = df_links.apply(obtenerlink,axis=1)\n",
    "        for item in df_links.iteritems():\n",
    "            url = item[1]\n",
    "            links += quote(url) + \",\"\n",
    "        links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    if(x[7]!= 0):\n",
    "        path_img = quote('./img/'+idn+'.png')\n",
    "        im = Image.open('./timelines/img/'+idn+'.png')\n",
    "        width, height = im.size\n",
    "        width = int(width*48/height)\n",
    "    \n",
    "    content  = \"createItem(\"+ quote(name_empresa) +\",\"+ path_img +\",\"+ str(width) +\",\"+ links + \")\"\n",
    "    \n",
    "    return \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start + \"}\"\n",
    "            \n",
    "#crear_evento(df.loc[118])\n",
    "#df.loc[118]\n",
    "filtro = df[' title'].str.contains(\"Banco Macro\")\n",
    "df[filtro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos...\n",
      "Guardando en archivo...\n",
      "Diferenciando versiones appendable y finalizada\n",
      "Version finalizada creada\n",
      "Versión appendable creada\n",
      "Finalizado!\n"
     ]
    }
   ],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "df_sin_repes = df.copy()\n",
    "filtro_repes = (df[' title'].str.contains(\"\\(\")) & (~(df[' title'].str.contains(\"\\(1\\)\")))\n",
    "df_sin_repes = df_sin_repes[~filtro_repes]\n",
    "\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "#f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "cosas = df_sin_repes.apply(crear_evento,axis=1)\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./timelines/empresas/trabajos_appendable.js\" \"./timelines/trabajos.js\"\n",
    "\n",
    "f2 = open(\"./timelines/empresas/trabajos.js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizer (OVERWRITES IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBSOLETE: images are not that heavy and look better without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded /tmp/magick-3689dVLyjnH2RKVf. Dimensions: 560 x 210  (with alpha). Format: lossless. Now saving...\n",
      "Saved file /tmp/magick-3689r4TsGY9Aa3Al\n",
      "convert-im6.q16: improper image header `./timelines/img/coto.png' @ error/png.c/ReadPNGImage/3954.\n",
      "convert-im6.q16: improper image header `./timelines/img/sheraton.png' @ error/png.c/ReadPNGImage/3954.\n"
     ]
    }
   ],
   "source": [
    "#!convert \"./timelines/empresas/img/*.png\" -filter Lanczos -resize x48 -sharpen 0x.5 -set filename:base \"%[basename]\" \"./timelines/empresas/img/%[filename:base].png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete _1 from filename for images that end in _1\n",
    "#!for file in `find . -name '*_1.png'` ; do mv \"$file\" \"${file%_1.png}.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline event images downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"http://www.digimouth.com/news/media/2011/09/google-logo.jpg\", \"local-filename.jpg\")\n",
    "# Quiero hacer una función que, dada una fila, me baje la imagen\n",
    "df_img=df.copy()\n",
    "df_img.dropna(subset=[' image'], inplace=True) \n",
    "falladas=[]\n",
    "assert(False)\n",
    "#path = \"./img_originales/\"\n",
    "def image_download(x):\n",
    "    empresa=sanitizar_nombre(x[2])\n",
    "    # donde x es una serie de Pandas\n",
    "    url = x[7].split('\":\"')[1]\n",
    "    url2 = url.split(\",\")[0][:-1]\n",
    "    print(url2)\n",
    "    try:\n",
    "        #response = requests.get(url2)\n",
    "        print(\"Downloading img for\",empresa)\n",
    "        urllib.request.urlretrieve(url2, path + empresa.lower() + \".png\")\n",
    "    except Exception as exc:\n",
    "        print('[!!!] {err}'.format(err=exc),\"retrieving img for\", empresa ,\"aborted\")\n",
    "        falladas.append(empresa)\n",
    "\n",
    "for index, row in df_img.iterrows():\n",
    "    print(index)\n",
    "    image_download(df_img.loc[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cgfsa', 'correo_oca', 'don_satur', 'sheraton', 'arcos_dorados_s.a.', 'telecentro']\n"
     ]
    }
   ],
   "source": [
    "print(falladas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not np.isnan(df.loc[1][7].isnull()):\n",
    "    print(\"Not a nan\")\n",
    "    print(df.loc[1][7])\n",
    "    urllib.request.urlretrieve(df.loc[1][7], path+df.loc[1][2].lower()+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTORIC EVENTS TIMELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./timelines/1unidad/1unidad.csv\",index_col=False)\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>importance</th>\n",
       "      <th>link</th>\n",
       "      <th>icon</th>\n",
       "      <th>image</th>\n",
       "      <th>date_display</th>\n",
       "      <th>lowthreshold</th>\n",
       "      <th>highthreshold</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1919-01-19 21:02:00</td>\n",
       "      <td>1919-01-19 21:02:00</td>\n",
       "      <td>7 al 14-01-1919: la Semana Trágica (cont.)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>65</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/file/d/1dPoj...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1922-06-03 21:02:00</td>\n",
       "      <td>1922-06-03 21:02:00</td>\n",
       "      <td>03-06-1922: Creación de la Dirección General d...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/file/d/1Imhr...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1929-10-24 21:02:00</td>\n",
       "      <td>1929-10-24 21:02:00</td>\n",
       "      <td>24-10-1929: Crack del 29 y Gran Depresión de l...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>65</td>\n",
       "      <td>[{\"url\":\"http://www.cooperacion2005.es/wp-cont...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1929-10-29 21:02:00</td>\n",
       "      <td>1929-10-29 21:02:00</td>\n",
       "      <td>29-10-1929: Crack del 29 y Gran Depresión (bis)</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>65</td>\n",
       "      <td>[{\"url\":\"https://drive.google.com/file/d/1CL0t...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>da</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4760-01-02 12:00:00</td>\n",
       "      <td>4760-01-02 12:00:00</td>\n",
       "      <td>476 Fin del Imperio Romano de Occidente y de l...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>[{\"url\":\"http://www.cooperacion2005.es/wp-cont...</td>\n",
       "      <td>shapes/triangle_gray.png</td>\n",
       "      <td>{\"src\":\"http://www.cooperacion2005.es/wp-conte...</td>\n",
       "      <td>ye</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               startdate              enddate  \\\n",
       "115  1919-01-19 21:02:00  1919-01-19 21:02:00   \n",
       "116  1922-06-03 21:02:00  1922-06-03 21:02:00   \n",
       "117  1929-10-24 21:02:00  1929-10-24 21:02:00   \n",
       "118  1929-10-29 21:02:00  1929-10-29 21:02:00   \n",
       "119  4760-01-02 12:00:00  4760-01-02 12:00:00   \n",
       "\n",
       "                                                 title description  \\\n",
       "115         7 al 14-01-1919: la Semana Trágica (cont.)     <p></p>   \n",
       "116  03-06-1922: Creación de la Dirección General d...     <p></p>   \n",
       "117  24-10-1929: Crack del 29 y Gran Depresión de l...     <p></p>   \n",
       "118    29-10-1929: Crack del 29 y Gran Depresión (bis)     <p></p>   \n",
       "119  476 Fin del Imperio Romano de Occidente y de l...     <p></p>   \n",
       "\n",
       "     importance                                               link  \\\n",
       "115          65  [{\"url\":\"https://drive.google.com/file/d/1dPoj...   \n",
       "116          60  [{\"url\":\"https://drive.google.com/file/d/1Imhr...   \n",
       "117          65  [{\"url\":\"http://www.cooperacion2005.es/wp-cont...   \n",
       "118          65  [{\"url\":\"https://drive.google.com/file/d/1CL0t...   \n",
       "119          60  [{\"url\":\"http://www.cooperacion2005.es/wp-cont...   \n",
       "\n",
       "                         icon  \\\n",
       "115  shapes/triangle_gray.png   \n",
       "116  shapes/triangle_gray.png   \n",
       "117  shapes/triangle_gray.png   \n",
       "118  shapes/triangle_gray.png   \n",
       "119  shapes/triangle_gray.png   \n",
       "\n",
       "                                                 image date_display  \\\n",
       "115  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "116  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "117  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "118  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           da   \n",
       "119  {\"src\":\"http://www.cooperacion2005.es/wp-conte...           ye   \n",
       "\n",
       "     lowthreshold  highthreshold  y_position  \n",
       "115             1            100           0  \n",
       "116             1            100           0  \n",
       "117             1            100           0  \n",
       "118             1            100           0  \n",
       "119             1            100           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrate events from Timeglider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_evento(x):\n",
    "    idn = sanitizar_nombre(x[2])\n",
    "    #print(idn)\n",
    "    #reemplazar NaNs en image por 0!!\n",
    "    path_img = quote(\"0\")\n",
    "    width = 0\n",
    "    start = quote(x[0][:-9])\n",
    "    name_empresa = x[2]\n",
    "    \n",
    "    if(multiples.count(x[2][:-4])==0):\n",
    "        links = \"[\"+ quote(obtenerlink(x)) + \"]\" #crear esta func\n",
    "    else:\n",
    "        #tengo multiples trabajos de esta empresa\n",
    "        #se podría manejar arriba con un for supongo? en algun lado me tengo que guardar los múltiples\n",
    "        name_empresa = x[2][:-4]\n",
    "        idn = idn[:-2]\n",
    "        filtro = df[' title'].str.contains(x[2][:-4])\n",
    "        df_links = df[filtro]\n",
    "        links = \"[\"\n",
    "        df_links = df_links.apply(obtenerlink,axis=1)\n",
    "        for item in df_links.iteritems():\n",
    "            url = item[1]\n",
    "            links += quote(url) + \",\"\n",
    "        links = links[:-1] + \"]\" #saco la , al pedo y agrego el corchete final\n",
    "    if(x[7]!= 0):\n",
    "        path_img = quote('./img/'+idn+'.png')\n",
    "        im = Image.open('./timelines/img/'+idn+'.png')\n",
    "        width, height = im.size\n",
    "        width = int(width*48/height)\n",
    "    \n",
    "    content  = \"createItem(\"+ quote(name_empresa) +\",\"+ path_img +\",\"+ str(width) +\",\"+ links + \")\"\n",
    "    \n",
    "    return \"{id: \" + quote(idn) + \", content: \" + content + \", start: \" + start + \"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_line = \"var items = new vis.DataSet([\"\n",
    "end_line = \"]);\"\n",
    "\n",
    "df_sin_repes = df.copy()\n",
    "filtro_repes = (df[' title'].str.contains(\"\\(\")) & (~(df[' title'].str.contains(\"\\(1\\)\")))\n",
    "df_sin_repes = df_sin_repes[~filtro_repes]\n",
    "\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "#f.write(start_line)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "print(\"Procesando base de datos...\")\n",
    "cosas = df_sin_repes.apply(crear_evento,axis=1)\n",
    "print(\"Guardando en archivo...\")\n",
    "for linea in cosas[:-1]:\n",
    "    #lleno con todos los eventos hasta el anteultimo\n",
    "    f.write(linea + \",\\n\")\n",
    "\n",
    "#La ULTIMA fila debe ir SIN COMA en la base finalizada, y CON COMA en la appendable!\n",
    "f.close()\n",
    "print(\"Diferenciando versiones appendable y finalizada\")\n",
    "!cp \"./timelines/empresas/trabajos_appendable.js\" \"./timelines/trabajos.js\"\n",
    "\n",
    "f2 = open(\"./timelines/empresas/trabajos.js\",\"a\")\n",
    "#aca va sin coma y con linea finalizadora\n",
    "f2.write(cosas.iloc[-1]+\"\\n\")\n",
    "f2.write(end_line)\n",
    "f2.close()\n",
    "print(\"Version finalizada creada\")\n",
    "\n",
    "#La version appendable va con coma y sin linea finalizadora\n",
    "f = open(\"./timelines/empresas/trabajos_appendable.js\", \"a\")\n",
    "f.write(cosas.iloc[-1]+\",\")\n",
    "f.close()\n",
    "print(\"Versión appendable creada\")\n",
    "print(\"Finalizado!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
